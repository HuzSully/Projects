{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\huzef\\OneDrive\\Documents\\Projects\\Projects\\data_science_code')\n",
    "\n",
    "from data_processor import DataProcessor\n",
    "from classification_models import *\n",
    "from convert_categorical_variables import CategoricalEncoder\n",
    "from evaluate_classification import ClassificationEvaluator\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = DataProcessor()\n",
    "train_df = data_processor.read_csv(r'C:\\Users\\huzef\\OneDrive\\Documents\\Projects\\Projects\\data\\titanic\\train.csv')\n",
    "test_df = data_processor.read_csv(r'C:\\Users\\huzef\\OneDrive\\Documents\\Projects\\Projects\\data\\titanic\\test.csv')\n",
    "gender_submission = data_processor.read_csv(r'C:\\Users\\huzef\\OneDrive\\Documents\\Projects\\Projects\\data\\titanic\\gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets successfully.\n",
      "Features and target variable split successfully.\n",
      "Features and target variable split successfully.\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = data_processor.train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "X_train, y_train = data_processor.split_features_target(train_data, 'Survived')\n",
    "X_test, y_test = data_processor.split_features_target(test_data, 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA/ Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(df_1):\n",
    "    df = df_1.copy()\n",
    "    df.drop('PassengerId', axis=1, inplace=True)\n",
    "\n",
    "    df['Surname'] = df['Name'].str.split(',').str[0]\n",
    "    df['FirstName'] = df['Name'].str.split(',').str[1]\n",
    "    df['Title'] = df['FirstName'].str.split('.').str[0]\n",
    "    df.drop(['Name', 'FirstName', 'Surname'], axis=1, inplace=True)\n",
    "    rare_titles = ['Rev', 'Dr', 'Major', 'Col', 'Mlle', 'Capt', 'Mme', 'the Countess', 'Lady', 'Sir', 'Jonkheer', 'Don']\n",
    "    df['Title'] = df['Title'].apply(lambda x: 'Miss' if x.strip() == 'Ms' else 'Rare' if x.strip() in rare_titles else x.strip())\n",
    "\n",
    "    df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "    df['Ticket_string'] = df['Ticket'].str.contains('[a-zA-Z]').astype(int)\n",
    "\n",
    "    df['Cabin'] = df['Cabin'].fillna('U')\n",
    "\n",
    "    most_common = df['Embarked'].mode()[0]\n",
    "    df['Embarked'] = df['Embarked'].fillna(most_common)\n",
    "\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "    df['Cabin_Letter'] = df['Cabin'].str.extract(r'([A-Za-z])')\n",
    "    df['Cabin_Number'] = df['Cabin'].str.extract(r'(\\d+)')\n",
    "    df['Cabin_Number'] = df['Cabin_Number'].fillna(0)\n",
    "    \n",
    "    df = df[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Title','Ticket_string','Cabin_Letter','Cabin_Number']]\n",
    "\n",
    "    encoder = CategoricalEncoder(df)\n",
    "    df = encoder.one_hot_encoding(['Embarked', 'Title', 'Cabin_Letter'])\n",
    "    df = df.drop(['Cabin_Letter_U'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_filt = eda(X_train)\n",
    "X_test_filt = eda(X_test)\n",
    "\n",
    "X_train_filt = X_train_filt[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Ticket_string',\n",
    "       'Cabin_Number', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
    "       'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare',\n",
    "       'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D',\n",
    "       'Cabin_Letter_E', 'Cabin_Letter_F', 'Cabin_Letter_G']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with different models:\n",
    "model_classes = {\n",
    "    'LogisticRegression': LogisticRegression,\n",
    "    'SGDClassifier': SGDClassifier,\n",
    "    'KNeighborsClassifier': KNeighborsClassifier,\n",
    "    'RandomForestClassifier': RandomForestClassifier,\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier,\n",
    "    'AdaBoostClassifier': AdaBoostClassifier,\n",
    "    'GaussianNB': GaussianNB,\n",
    "    'SVC': SVC,\n",
    "    'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis,\n",
    "    'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis,\n",
    "    'MLPClassifier': MLPClassifier,\n",
    "    'XGBClassifier': XGBClassifier\n",
    "}\n",
    "\n",
    "# Create a model instance and perform operations:\n",
    "for model_name, model_class in model_classes.items():\n",
    "    print(f\"Using {model_name}\")\n",
    "    model = ModelTrainer(model_class, random_state=42)\n",
    "    # Add data loading, training, prediction, etc.\n",
    "    print(f\"Model parameters: {model.get_params()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegressionModel()\n",
    "log_reg_model.set_params(random_state=42, max_iter=1000) \n",
    "log_reg_model.train(X_train_filt, y_train)\n",
    "log_reg_predict = log_reg_model.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.156086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.151405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.142978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.121433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.065480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  Importance\n",
       "0      Fare    0.156086\n",
       "1  Title_Mr    0.151405\n",
       "2       Sex    0.142978\n",
       "3       Age    0.121433\n",
       "4    Pclass    0.065480"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestModel(random_state=42)\n",
    "rf_model.train(X_train_filt, y_train)\n",
    "best_params = rf_model.tune_hyperparameters(X_train_filt, y_train, param_grid={'n_estimators': [100, 200], 'max_depth': [10, 20]})\n",
    "rf_model_predict = rf_model.predict(X_test_filt)\n",
    "(rf_model.get_feature_importances()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayesModel()\n",
    "naive_bayes.train(X_train_filt, y_train)\n",
    "naive_bayes_predict = naive_bayes.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_filt)\n",
    "X_test_scaled = scaler.transform(X_test_filt)\n",
    "\n",
    "svm_model = SVMModel(random_state=42)\n",
    "svm_model.train(X_train_scaled, y_train)\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "best_params = svm_model.tune_hyperparameters(X_train_scaled, y_train, param_grid=param_grid)\n",
    "svm_model_predict = svm_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = GBMModel(random_state=42)\n",
    "gbm_model.train(X_train_filt, y_train)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "best_params = gbm_model.tune_hyperparameters(X_train_filt, y_train, param_grid=param_grid)\n",
    "\n",
    "gbm_model_predict = gbm_model.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_filt)\n",
    "X_test_scaled = scaler.transform(X_test_filt)\n",
    "\n",
    "knn_model = KNNModel()\n",
    "\n",
    "knn_model.train(X_train_scaled, y_train)\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "best_params = knn_model.tune_hyperparameters(X_train_scaled, y_train, param_grid=param_grid)\n",
    "knn_model_predict = knn_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huzef\\Anaconda3\\envs\\general2\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\huzef\\Anaconda3\\envs\\general2\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ada_model = AdaBoostModel(random_state=42)\n",
    "ada_model.train(X_train_filt, y_train)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0]\n",
    "}\n",
    "best_params = ada_model.tune_hyperparameters(X_train_filt, y_train, param_grid=param_grid)\n",
    "ada_model_predict = ada_model.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huzef\\Anaconda3\\envs\\general2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "c:\\Users\\huzef\\Anaconda3\\envs\\general2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "qda_model = QDAModel()\n",
    "qda_model.train(X_train_filt, y_train)\n",
    "param_grid = {\n",
    "    'reg_param': [0.0, 0.01, 0.1, 1.0],\n",
    "    'tol': [1e-4, 1e-3, 1e-2]\n",
    "}\n",
    "best_params = qda_model.tune_hyperparameters(X_train_filt, y_train, param_grid=param_grid)\n",
    "qda_model_predict = qda_model.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LDAModel()\n",
    "lda_model.train(X_train_filt, y_train)\n",
    "\n",
    "param_grid = [\n",
    "    {'solver': ['svd'], 'shrinkage': [None]},  # 'svd' solver doesn't support shrinkage\n",
    "    {'solver': ['lsqr', 'eigen'], 'shrinkage': ['auto', 0.1, 0.5]},\n",
    "    {'solver': ['lsqr', 'eigen'], 'shrinkage': [None]}  # Optionally include no shrinkage for these solvers\n",
    "]\n",
    "\n",
    "best_params = lda_model.tune_hyperparameters(X_train_filt, y_train, param_grid=param_grid)\n",
    "print(\"Best parameters: \", best_params)\n",
    "\n",
    "lda_model_predict = lda_model.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filt = X_train_filt.apply(lambda col: col.astype('category').cat.codes if col.dtype == 'object' else col)\n",
    "X_test_filt = X_test_filt.apply(lambda col: col.astype('category').cat.codes if col.dtype == 'object' else col)\n",
    "\n",
    "xgb_model = XGBoostModel(random_state=42)\n",
    "xgb_model.train(X_train_filt, y_train)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "best_params = xgb_model.tune_hyperparameters(X_train_filt, y_train, param_grid=param_grid)\n",
    "xgb_model_predict = xgb_model.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huzef\\Anaconda3\\envs\\general2\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nn_model = NeuralNetworkModel(random_state=42)\n",
    "nn_model.train(X_train_filt, y_train)\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1]\n",
    "}\n",
    "best_params = nn_model.tune_hyperparameters(X_train_filt, y_train, param_grid=param_grid)\n",
    "nn_model_predict = nn_model.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>90\\t15\\n16\\t58</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>88\\t17\\n15\\t59</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>89\\t16\\n16\\t58</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>88\\t17\\n16\\t58</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBM</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>91\\t14\\n18\\t56</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF Model</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>92\\t13\\n19\\t55</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.758170</td>\n",
       "      <td>84\\t21\\n16\\t58</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>82\\t23\\n15\\t59</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>82\\t23\\n17\\t57</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.670886</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.692810</td>\n",
       "      <td>79\\t26\\n21\\t53</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>88\\t17\\n29\\t45</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall  F1 Score  \\\n",
       "9               XGBoost  0.826816   0.794521  0.783784  0.789116   \n",
       "0   Logistic Regression  0.821229   0.776316  0.797297  0.786667   \n",
       "3                   SVM  0.821229   0.783784  0.783784  0.783784   \n",
       "8                   LDA  0.815642   0.773333  0.783784  0.778523   \n",
       "4                   GBM  0.821229   0.800000  0.756757  0.777778   \n",
       "1              RF Model  0.821229   0.808824  0.743243  0.774648   \n",
       "6              AdaBoost  0.793296   0.734177  0.783784  0.758170   \n",
       "2           Naive Bayes  0.787709   0.719512  0.797297  0.756410   \n",
       "10       Neural Network  0.776536   0.712500  0.770270  0.740260   \n",
       "5                   KNN  0.737430   0.670886  0.716216  0.692810   \n",
       "7                   QDA  0.743017   0.725806  0.608108  0.661765   \n",
       "\n",
       "   Confusion Matrix ROC AUC  \n",
       "9    90\\t15\\n16\\t58    None  \n",
       "0    88\\t17\\n15\\t59    None  \n",
       "3    89\\t16\\n16\\t58    None  \n",
       "8    88\\t17\\n16\\t58    None  \n",
       "4    91\\t14\\n18\\t56    None  \n",
       "1    92\\t13\\n19\\t55    None  \n",
       "6    84\\t21\\n16\\t58    None  \n",
       "2    82\\t23\\n15\\t59    None  \n",
       "10   82\\t23\\n17\\t57    None  \n",
       "5    79\\t26\\n21\\t53    None  \n",
       "7    88\\t17\\n29\\t45    None  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = ClassificationEvaluator(y_true=y_test)\n",
    "evaluator.add_model('Logistic Regression', log_reg_predict)\n",
    "evaluator.add_model('RF Model', rf_model_predict)\n",
    "evaluator.add_model('Naive Bayes', naive_bayes_predict)\n",
    "evaluator.add_model('SVM', svm_model_predict)\n",
    "evaluator.add_model('GBM', gbm_model_predict)\n",
    "evaluator.add_model('KNN', knn_model_predict)\n",
    "evaluator.add_model('AdaBoost', ada_model_predict)\n",
    "evaluator.add_model('QDA', qda_model_predict)\n",
    "evaluator.add_model('LDA', lda_model_predict)\n",
    "evaluator.add_model('XGBoost', xgb_model_predict)\n",
    "evaluator.add_model('Neural Network', nn_model_predict)\n",
    "evaluator.evaluate_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
