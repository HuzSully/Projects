{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Models: GBMModel\n",
      "SVMModel\n",
      "NaiveBayesModel\n",
      "LogisticRegressionModel\n",
      "RandomForestModel\n",
      "KNNModel\n",
      "AdaBoostModel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\huzef\\OneDrive\\Documents\\Projects\\Projects\\data_science_code')\n",
    "\n",
    "from data_processor import DataProcessor\n",
    "from classification_models import *\n",
    "from convert_categorical_variables import CategoricalEncoder\n",
    "from evaluate_classification import ClassificationEvaluator\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor = DataProcessor()\n",
    "train_df = data_processor.read_csv(r'C:\\Users\\huzef\\OneDrive\\Documents\\Projects\\Projects\\data\\titanic\\train.csv')\n",
    "test_df = data_processor.read_csv(r'C:\\Users\\huzef\\OneDrive\\Documents\\Projects\\Projects\\data\\titanic\\test.csv')\n",
    "gender_submission = data_processor.read_csv(r'C:\\Users\\huzef\\OneDrive\\Documents\\Projects\\Projects\\data\\titanic\\gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets successfully.\n",
      "Features and target variable split successfully.\n",
      "Features and target variable split successfully.\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = data_processor.train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "X_train, y_train = data_processor.split_features_target(train_data, 'Survived')\n",
    "X_test, y_test = data_processor.split_features_target(test_data, 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA/ Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(df_1):\n",
    "    df = df_1.copy()\n",
    "    df.drop('PassengerId', axis=1, inplace=True)\n",
    "\n",
    "    df['Surname'] = df['Name'].str.split(',').str[0]\n",
    "    df['FirstName'] = df['Name'].str.split(',').str[1]\n",
    "    df['Title'] = df['FirstName'].str.split('.').str[0]\n",
    "    df.drop(['Name', 'FirstName', 'Surname'], axis=1, inplace=True)\n",
    "    rare_titles = ['Rev', 'Dr', 'Major', 'Col', 'Mlle', 'Capt', 'Mme', 'the Countess', 'Lady', 'Sir', 'Jonkheer', 'Don']\n",
    "    df['Title'] = df['Title'].apply(lambda x: 'Miss' if x.strip() == 'Ms' else 'Rare' if x.strip() in rare_titles else x.strip())\n",
    "\n",
    "    df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "    df['Ticket_string'] = df['Ticket'].str.contains('[a-zA-Z]').astype(int)\n",
    "\n",
    "    df['Cabin'] = df['Cabin'].fillna('U')\n",
    "\n",
    "    most_common = df['Embarked'].mode()[0]\n",
    "    df['Embarked'] = df['Embarked'].fillna(most_common)\n",
    "\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "    df['Cabin_Letter'] = df['Cabin'].str.extract(r'([A-Za-z])')\n",
    "    df['Cabin_Number'] = df['Cabin'].str.extract(r'(\\d+)')\n",
    "    df['Cabin_Number'] = df['Cabin_Number'].fillna(0)\n",
    "    \n",
    "    df = df[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Title','Ticket_string','Cabin_Letter','Cabin_Number']]\n",
    "\n",
    "    encoder = CategoricalEncoder(df)\n",
    "    df = encoder.one_hot_encoding(['Embarked', 'Title', 'Cabin_Letter'])\n",
    "    df = df.drop(['Cabin_Letter_U'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_filt = eda(X_train)\n",
    "X_test_filt = eda(X_test)\n",
    "\n",
    "X_train_filt = X_train_filt[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Ticket_string',\n",
    "       'Cabin_Number', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
    "       'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare',\n",
    "       'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D',\n",
    "       'Cabin_Letter_E', 'Cabin_Letter_F', 'Cabin_Letter_G']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegressionModel()\n",
    "log_reg_model.set_params(random_state=42, max_iter=1000) \n",
    "log_reg_model.train(X_train_filt, y_train)\n",
    "log_reg_predict = log_reg_model.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.156086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.151405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.142978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.121433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.065480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature  Importance\n",
       "0      Fare    0.156086\n",
       "1  Title_Mr    0.151405\n",
       "2       Sex    0.142978\n",
       "3       Age    0.121433\n",
       "4    Pclass    0.065480"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestModel(random_state=42)\n",
    "rf_model.train(X_train_filt, y_train)\n",
    "best_params = rf_model.tune_hyperparameters(X_train_filt, y_train, param_grid={'n_estimators': [100, 200], 'max_depth': [10, 20]})\n",
    "rf_model_predict = rf_model.predict(X_test_filt)\n",
    "(rf_model.get_feature_importances()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayesModel()\n",
    "naive_bayes.train(X_train_filt, y_train)\n",
    "naive_bayes_predict = naive_bayes.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_filt)\n",
    "X_test_scaled = scaler.transform(X_test_filt)\n",
    "\n",
    "svm_model = SVMModel(random_state=42)\n",
    "svm_model.train(X_train_scaled, y_train)\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "best_params = svm_model.tune_hyperparameters(X_train_scaled, y_train, param_grid=param_grid)\n",
    "svm_model_predict = svm_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = GBMModel(random_state=42)\n",
    "gbm_model.train(X_train_filt, y_train)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "best_params = gbm_model.tune_hyperparameters(X_train_filt, y_train, param_grid=param_grid)\n",
    "\n",
    "gbm_model_predict = gbm_model.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_filt)\n",
    "X_test_scaled = scaler.transform(X_test_filt)\n",
    "\n",
    "knn_model = KNNModel()\n",
    "\n",
    "knn_model.train(X_train_scaled, y_train)\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "best_params = knn_model.tune_hyperparameters(X_train_scaled, y_train, param_grid=param_grid)\n",
    "knn_model_predict = knn_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huzef\\Anaconda3\\envs\\general2\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\huzef\\Anaconda3\\envs\\general2\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ada_model = AdaBoostModel(random_state=42)\n",
    "ada_model.train(X_train_filt, y_train)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0]\n",
    "}\n",
    "best_params = ada_model.tune_hyperparameters(X_train_filt, y_train, param_grid=param_grid)\n",
    "ada_model_predict = ada_model.predict(X_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>88\\t17\\n15\\t59</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>89\\t16\\n16\\t58</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBM</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>91\\t14\\n18\\t56</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF Model</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>92\\t13\\n19\\t55</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.758170</td>\n",
       "      <td>84\\t21\\n16\\t58</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>82\\t23\\n15\\t59</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.670886</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.692810</td>\n",
       "      <td>79\\t26\\n21\\t53</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  \\\n",
       "0  Logistic Regression  0.821229   0.776316  0.797297  0.786667   \n",
       "3                  SVM  0.821229   0.783784  0.783784  0.783784   \n",
       "4                  GBM  0.821229   0.800000  0.756757  0.777778   \n",
       "1             RF Model  0.821229   0.808824  0.743243  0.774648   \n",
       "6             AdaBoost  0.793296   0.734177  0.783784  0.758170   \n",
       "2          Naive Bayes  0.787709   0.719512  0.797297  0.756410   \n",
       "5                  KNN  0.737430   0.670886  0.716216  0.692810   \n",
       "\n",
       "  Confusion Matrix ROC AUC  \n",
       "0   88\\t17\\n15\\t59    None  \n",
       "3   89\\t16\\n16\\t58    None  \n",
       "4   91\\t14\\n18\\t56    None  \n",
       "1   92\\t13\\n19\\t55    None  \n",
       "6   84\\t21\\n16\\t58    None  \n",
       "2   82\\t23\\n15\\t59    None  \n",
       "5   79\\t26\\n21\\t53    None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = ClassificationEvaluator(y_true=y_test)\n",
    "evaluator.add_model('Logistic Regression', log_reg_predict)\n",
    "evaluator.add_model('RF Model', rf_model_predict)\n",
    "evaluator.add_model('Naive Bayes', naive_bayes_predict)\n",
    "evaluator.add_model('SVM', svm_model_predict)\n",
    "evaluator.add_model('GBM', gbm_model_predict)\n",
    "evaluator.add_model('KNN', knn_model_predict)\n",
    "evaluator.add_model('AdaBoost', ada_model_predict)\n",
    "evaluator.evaluate_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
